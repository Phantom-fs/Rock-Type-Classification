{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from torchvision.models import DenseNet169_Weights\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from colorama import Fore, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Results libraries import\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# colorama\n",
    "red = Fore.RED\n",
    "green = Fore.GREEN\n",
    "blue = Fore.BLUE\n",
    "yellow = Fore.YELLOW\n",
    "cyan = Fore.CYAN\n",
    "\n",
    "reset = Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "d = \".../Rocks/\"\n",
    "\n",
    "loc = \"PyDL_C\"\n",
    "\n",
    "# Sub-Categorized data\n",
    "train_dir = d + loc + \"/data/train\"\n",
    "test_dir = d + loc + \"/data/test\"\n",
    "valid_dir = d + loc + \"/data/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting the seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(f'{blue}Global seed set to : {yellow}{seed}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Image dimentions\n",
    "img_dimen = (256, 256)\n",
    "bs = 16\n",
    "max_acc_ac = 0\n",
    "y_pred = []\n",
    "y_true = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean & std\n",
    "# preprocessing | get the data mean and std for normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_dimen),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "calc_ms = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "loader_ms = torch.utils.data.DataLoader(dataset=calc_ms, batch_size=bs, shuffle=False)\n",
    "\n",
    "mean_calc = 0\n",
    "std_calc = 0\n",
    "total_images = 0\n",
    "\n",
    "for images, _ in loader_ms:\n",
    "    batch_samples = images.size(0)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean_calc += images.mean(2).sum(0)\n",
    "    std_calc += images.std(2).sum(0)\n",
    "    total_images += batch_samples\n",
    "\n",
    "mean_calc /= total_images\n",
    "std_calc /= total_images\n",
    "\n",
    "print(f'{blue}mean: {yellow}{mean_calc}')\n",
    "print(f'{blue}std: {yellow}{std_calc}{reset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# org mean & std values\n",
    "#mean_calc = [0.485, 0.456, 0.406]\n",
    "#std_calc = [0.229, 0.224, 0.255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data transformations training set\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(img_dimen),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_calc, std_calc)\n",
    "])\n",
    "\n",
    "# Data transformations for validation and test sets\n",
    "transform_common = transforms.Compose([\n",
    "    transforms.Resize(img_dimen),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_calc, std_calc)\n",
    "])\n",
    "\n",
    "# Image dataset\n",
    "dataset_train = datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "dataset_test = datasets.ImageFolder(root=test_dir, transform=transform_common)\n",
    "dataset_valid = datasets.ImageFolder(root=valid_dir, transform=transform_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "max_epoch = 50\n",
    "batch_size = bs\n",
    "learningRate = 0.0001\n",
    "WeightDecay = 1e-08\n",
    "\n",
    "# All Information\n",
    "print(f'{blue}Epochs: {yellow}{max_epoch}{reset}')\n",
    "print(f'{blue}Batch size: {yellow}{batch_size}{reset}')\n",
    "print(f'{blue}Learning rate: {yellow}{learningRate}{reset}')\n",
    "print(f'{blue}Weight decay: {yellow}{WeightDecay}{reset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DenseNet\n",
    "model = models.densenet169(weights=DenseNet169_Weights.IMAGENET1K_V1)\n",
    "\n",
    "num_classes = len(dataset_train.classes)\n",
    "\n",
    "# Freeze the model parameters\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "# change the last layer of the model\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(in_features=num_ftrs, out_features=num_classes)\n",
    "\n",
    "# Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learningRate, weight_decay=WeightDecay)\n",
    "print(f'{blue}Device: {yellow}{device}{reset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "\n",
    "# Loss metrics\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "# Accuracy metrics\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "# best model score\n",
    "max_score = 0\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    model.train()\n",
    "\n",
    "    # Metrics initialization\n",
    "    running_loss = 0.0\n",
    "    num_correct = 0\n",
    "\n",
    "    # TRAINING\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Predictions | forward pass | OUTPUT\n",
    "        outputs = model(inputs)\n",
    "        # Loss | backward pass | GRADIENT\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # Count correct predictions\n",
    "        num_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Training loss\n",
    "    train_lss = running_loss / len(train_loader)\n",
    "    train_loss.append(train_lss)\n",
    "\n",
    "    # Training accuracy\n",
    "    train_accuracy = 100 * num_correct / len(train_loader.dataset)\n",
    "    train_acc.append(train_accuracy)\n",
    "    # ---------------------------------------------------------------------------\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    valid_loss = 0\n",
    "\n",
    "    # VALIDATION\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Predictions\n",
    "            outputs = model(inputs)\n",
    "            # Count correct predictions\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Loss\n",
    "            valid_loss += criterion(outputs, labels).item()\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #Validation loss\n",
    "    val_lss = valid_loss / len(valid_loader)\n",
    "    val_loss.append(val_lss)\n",
    "\n",
    "    # Validation accuracy\n",
    "    val_accuracy = 100 * correct / len(valid_loader.dataset)\n",
    "    val_acc.append(val_accuracy)\n",
    "    # --------------------------------------------------------------------------\n",
    "\n",
    "    print(f'{cyan}\\nEPOCH {epoch + 1}{reset}')\n",
    "    print(f\"Loss: {red}{train_lss}{reset}, Validation Accuracy: {red}{val_accuracy}%{reset}, Training Accuracy: {red}{train_accuracy}%\")\n",
    "\n",
    "    # Save the best model\n",
    "    if val_accuracy > max_score:\n",
    "        max_score = val_accuracy\n",
    "        path = d + loc + '/models/DenseNet_169_T.pth'\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f'{green}Improvement! Model saved!{reset}')\n",
    "\n",
    "print(f'{yellow}Training finished!\\n')\n",
    "\n",
    "# Save the Final model\n",
    "path = d + loc + '/models/DenseNet_169_F.pth'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Graph of training and validation: loss and accuracy | dual plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Loss plot\n",
    "ax1.set_title(\"Loss\")\n",
    "ax1.plot(val_loss, color='red', label='Validation loss', linestyle='dashed')\n",
    "ax1.plot(train_loss, color='orange', label='Training loss')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel(\"Iterations\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.set_title(\"Accuracy\")\n",
    "ax2.plot(val_acc, color='red', label='Validation accuracy', linestyle='dashed')\n",
    "ax2.plot(train_acc, color='orange', label='Training accuracy')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel(\"Iterations\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TESTING on FINAL Model\n",
    "acc_final = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "y_pred_F = []\n",
    "y_true_F = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Predictions | forward pass | OUTPUT\n",
    "        outputs = model(inputs)\n",
    "        # Count correct predictions\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        y_pred_F.extend(predicted.tolist())\n",
    "        y_true_F.extend(labels.tolist())\n",
    "\n",
    "acc_final = 100 * correct / total\n",
    "print(f\"{blue}Test Accuracy (Final Model): {red}{100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TESTING on BEST Model\n",
    "b_model = models.densenet169(weights=DenseNet169_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = b_model.classifier.in_features\n",
    "b_model.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "b_model.load_state_dict(torch.load(d + loc + '/models/DenseNet_169_T.pth'))\n",
    "\n",
    "acc_best = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "y_pred_B = []\n",
    "y_true_B = []\n",
    "\n",
    "b_model.eval()\n",
    "b_model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Predictions | forward pass | OUTPUT\n",
    "        outputs = b_model(inputs)\n",
    "        # Count correct predictions\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        y_pred_B.extend(predicted.tolist())\n",
    "        y_true_B.extend(labels.tolist())\n",
    "\n",
    "acc_best = 100 * correct / total\n",
    "print(f\"{blue}Test Accuracy (Best Model): {red}{100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if acc_final > acc_best:\n",
    "    max_acc_ac = acc_final\n",
    "    y_pred = y_pred_F\n",
    "    y_true = y_true_F\n",
    "    print(f\"{blue}Best Accuracy on Final Model! {red}{max_acc_ac}{reset}\")\n",
    "    \n",
    "else:\n",
    "    model = b_model\n",
    "    max_acc_ac = acc_best\n",
    "    y_pred = y_pred_B\n",
    "    y_true = y_true_B\n",
    "    print(f\"{blue}Best Accuracy on Highest Accuracy Validation Model! {red}{max_acc_ac}{reset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(f\"{blue}Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=dataset_test.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# F-1 Score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"{blue}F-1 Score: {red}{f1 * 100}%{reset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Precision\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "print(f\"{blue}Precision: {red}{precision * 100}%{reset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recall | Sensitivity\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "print(f\"{blue}Recall: {red}{recall * 100}%{reset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tp_calc (y_true, y_pred, class_label):\n",
    "    tp = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == class_label and y_pred[i] == class_label:\n",
    "            tp += 1\n",
    "    return tp\n",
    "    \n",
    "def tn_calc (y_true, y_pred, class_label):\n",
    "    tn = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] != class_label and y_pred[i] != class_label:\n",
    "            tn += 1\n",
    "    return tn\n",
    "    \n",
    "def fp_calc (y_true, y_pred, class_label):\n",
    "    fp = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] != class_label and y_pred[i] == class_label:\n",
    "            fp += 1\n",
    "    return fp\n",
    "    \n",
    "def fn_calc (y_true, y_pred, class_label):\n",
    "    fn = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == class_label and y_pred[i] != class_label:\n",
    "            fn += 1\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_specificity(y_true, y_pred, class_index):\n",
    "    # Convert y_true and y_pred to numpy arrays if they are lists\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Identify true positive, false positive, true negative, and false negative counts\n",
    "    # true_positive = np.sum((y_true == class_index) & (y_pred == class_index))\n",
    "    false_positive = np.sum((y_true != class_index) & (y_pred == class_index))\n",
    "    true_negative = np.sum((y_true != class_index) & (y_pred != class_index))\n",
    "    # false_negative = np.sum((y_true == class_index) & (y_pred != class_index))\n",
    "\n",
    "    # Calculate specificity\n",
    "    specificity = true_negative / (true_negative + false_positive)\n",
    "\n",
    "    return specificity\n",
    "\n",
    "def calculate_multi_class_specificity(y_true, y_pred):\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    specificity_scores = []\n",
    "\n",
    "    for class_index in range(num_classes):\n",
    "        specificity = calculate_specificity(y_true, y_pred, class_index)\n",
    "        specificity_scores.append(specificity)\n",
    "\n",
    "    # Calculate the average specificity across all classes\n",
    "    average_specificity = np.mean(specificity_scores)\n",
    "\n",
    "    return average_specificity, specificity_scores\n",
    "\n",
    "\n",
    "# Calculate the specificity\n",
    "average_specificity, specificity_scores = calculate_multi_class_specificity(y_true, y_pred)\n",
    "print(f\"{blue}Specificity: {red}{average_specificity * 100}%{reset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dataset_test.classes)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "plt.title(\"DenseNet-169\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
